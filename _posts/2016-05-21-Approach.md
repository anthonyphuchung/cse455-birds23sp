---
layout: post
subtitle: Approach, Previous Work, ResNet18, AlexNet, Code
---
# Previous Work
Our overall objective and goal was to train a neural network classifier that was accurate at classifying bird species based on bird images. We referenced [tutorial 3](https://colab.research.google.com/drive/1EBz4feoaUvz-o_yeMI27LEQBkvrXNc_4?usp=sharing) and [tutorial 4](https://colab.research.google.com/drive/1kHo8VT-onDxbtS3FM77VImG35h_K_Lav?usp=sharing) and applied it to two different pre-trained models: [AlexNet](https://pytorch.org/hub/pytorch_vision_alexnet/) and [ResNet18](https://pytorch.org/vision/main/models/generated/torchvision.models.resnet18.html). In each model, we performed the following pre-processing prior to the training:
```python
transform_train = transforms.Compose([
        transforms.RandomResizedCrop(size=480, scale=(0.95, 1.0)),
        transforms.RandomRotation(15),
        transforms.RandomHorizontalFlip(),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406],
                             std=[0.229, 0.224, 0.225])
])

transform_val = transforms.Compose([
        transforms.Resize(480),
        transforms.CenterCrop(224),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406],
                             std=[0.229, 0.224, 0.225])
])

transform_test = transforms.Compose([
        transforms.Resize(480),
        transforms.CenterCrop(224),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406],
                             std=[0.229, 0.224, 0.225])
])
```


# AlexNet
We started with AlexNet as it provided a manageable entry point into convolutional neural networks for image classification. It is similar to LeNet by Yann LeCun but has more filters per layer and is deeper. AlexNet has several layers that perform different feature extraction with varying sized, stacked convolutional filters. The low-level features extract lines and oriented edges and the first convolutional kernel is 11x11x3. The mid-level features combine edges to make curves and shapes. The high-level features combine shapes to make objects and scenes. These layers have convolution kernels of 5x5 and 3x3 as well as max pooling and RELU activations, which are after every convolutional and fully-connected layer.
The final layers are fully connected and are the predictors that process features and make output predictions.

When training with AlexNet, we replaced the final classifier layer with a new linear layer with the correct number of label outputs (555) and retrained with the bird dataset. We also replaced and retrain the second classifier in the network so it is not as dense. For optimizers, we initially used the Adam optimizer, which tends to converge faster, but found better performance using stochastic gradient descent (SGD). During the testing phase, we fine-tuned the parameters to find the correct values in which AlexNet would yield the best results.


# ResNet18

We wanted to explore a more powerful neural network so we switched our classification program to use ResNet18. ResNet is a residual network with heavy batch normalization. This means that we normalize relative to images in the batch and perform feature extraction based off of how different an image is relative to the other images in the batch we're comparing to. We used stochastic gradient descent which means we draw a random batch of images, so the way we’re comparing the images changes and we are comparing on slightly shifted images. This idea is called data augmentation which makes it harder for the network to overfit to the raw pixel values or batch images and forces the network to actually learn the underlying distributions in the data to fit the particular loss we’re using and perform better feature extraction. Unlike AlexNet, ResNet has convolution kernels that are all 3x3 and ResNet-18 has 18 layers. 

In our implementation, we removed the last fully connected layer of the network and then we re-trained with a stochastic gradient descent (SGD) optimizer on the bird dataset. Similar to AlexNet, we tested varying learning rate, decay, and momentum, to find the best values for ResNet18 to produce the highest accuracy.

# Code
Below is the code we implemented for the Kaggle competition:

```python
import torch
import torchvision
import torchvision.transforms as transforms
import matplotlib.pyplot as plt
import numpy as np
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim

device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
PATH = '/kaggle/input/birds23sp/birds/'

checkpoints = '/kaggle/working/checkpoints/';
if not os.path.exists(checkpoints):
    os.makedirs(checkpoints)

train_paths = []
file_list = glob.glob(PATH + 'train/*')
for f in file_list:
    img_list = glob.glob(f + '/*')
    for i in img_list:
        class_name = i.split("/")[-1]
        train_paths.append(i)

transform_train = transforms.Compose([
        transforms.RandomResizedCrop(size=480, scale=(0.95, 1.0)),
        transforms.RandomRotation(15),
        transforms.RandomHorizontalFlip(),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406],
                             std=[0.229, 0.224, 0.225])
])

transform_val = transforms.Compose([
        transforms.Resize(480),
        transforms.CenterCrop(224),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406],
                             std=[0.229, 0.224, 0.225])
])

transform_test = transforms.Compose([
        transforms.Resize(480),
        transforms.CenterCrop(224),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406],
                             std=[0.229, 0.224, 0.225])
])

indices = list(np.arange(len(train_paths)))
random.shuffle(indices)
train_set_size = int(len(indices) * 0.8)  # Random split data to 80% training and 20% validation
valid_set_size = len(indices) - train_set_size
train_indices, val_indices = torch.utils.data.random_split(indices, [train_set_size, valid_set_size])

dataset_train = torchvision.datasets.ImageFolder(root=PATH+'train', transform=transform_train)
train_set = torch.utils.data.Subset(dataset_train, train_indices)
train_loader = DataLoader(dataset=train_set, batch_size=64, shuffle=True, num_workers=2)

dataset_val = torchvision.datasets.ImageFolder(root=PATH+'train', transform=transform_val)
val_set = torch.utils.data.Subset(dataset_train, val_indices)
val_loader = DataLoader(dataset=val_set, batch_size=1, shuffle=False, num_workers=2)
                
test_set = torchvision.datasets.ImageFolder(root=PATH+'test', transform=transform_test)
test_loader = DataLoader(dataset=test_set, batch_size=1, shuffle=False, num_workers=2)

dataiter = iter(train_loader)
images, labels = next(dataiter)
images = images[:8]
print(images.size())

def imshow(img):
    npimg = img.numpy()
    plt.imshow(np.transpose(npimg, (1, 2, 0)))
    plt.show()

# Show images
imshow(torchvision.utils.make_grid(images))

def train(net, dataloader, epochs=1, start_epoch=0, lr=0.01, momentum=0.9, decay=0.0005, verbose=1,
         print_every=10, state=None, schedule={}, checkpoint_path=None):
    net.to(device)
    net.train()
    losses = []
    class_counts = labels_df['class'].value_counts().tolist()
    class_weights = 1./torch.tensor(class_counts, dtype=torch.float)
    class_weights = class_weights.to(device)
    criterion = nn.CrossEntropyLoss(weight=class_weights)
    optimizer = optim.SGD(net.parameters(), lr=lr, momentum=momentum, weight_decay=decay)

    # Load previous training state
    if state:
        net.load_state_dict(state['net'])
        optimizer.load_state_dict(state['optimizer'])
        start_epoch = state['epoch']
        losses = state['losses']
        
    # Fast forward lr schedule through already trained epochs
    for epoch in range(start_epoch):
        if epoch in schedule:
            print ("Learning rate: %f"% schedule[epoch])
            for g in optimizer.param_groups:
                g['lr'] = schedule[epoch]

    for epoch in range(start_epoch, epochs):
        sum_loss = 0.0
        correct = 0

        # Update learning rate when scheduled
        if epoch in schedule:
            print ("Learning rate: %f"% schedule[epoch])
            for g in optimizer.param_groups:
                g['lr'] = schedule[epoch]

        for i, batch in enumerate(dataloader, 0):
            inputs, labels = batch[0].to(device), batch[1].to(device)

            optimizer.zero_grad()

            outputs = net(inputs)
            _, predicted = outputs.max(1)
            loss = criterion(outputs, labels)
            loss.backward()  # autograd magic, computes all the partial derivatives
            optimizer.step() # takes a step in gradient direction

            losses.append(loss.item())
            sum_loss += loss.item()
            correct += (predicted == labels).sum()

            if i % print_every == print_every-1: 
                if verbose:
                    print('[epoch = %d, batch = %d] loss: %.3f' % (epoch, i + 1, sum_loss / print_every))
                sum_loss = 0.0
        print('[epoch %d finished] accuracy: %.3f' % (epoch, correct / len(dataloader.sampler)))
        
        if checkpoint_path:
            state = {'epoch': epoch+1, 'net': net.state_dict(), 'optimizer': optimizer.state_dict(), 'losses': losses}
            print("=> Saving checkpoint")
            torch.save(state, checkpoint_path+'checkpoint-%d.pkl'%(epoch+1))
    return losses

def accuracy(net, dataloader):
    net.to(device)
    net.eval()
    correct = 0
    total = 0
    with torch.no_grad():
        for batch in dataloader:
            images, labels = batch[0].to(device), batch[1].to(device)
            outputs = net(images)
            _, predicted = torch.max(outputs.data, 1)
            total += labels.size(0)
            correct += (predicted == labels).sum().item()
    return correct/total

def smooth(x, size):
    return np.convolve(x, np.ones(size)/size, mode='valid')

# This is used for generating the csv to submit
class_to_idx = dataset_train.class_to_idx
idx_to_class = {int(v): int(k) for k, v in class_to_idx.items()}

def predict(net, dataloader, ofname):
    out = open(ofname, 'w')
    out.write("path,class\n")
    net.to(device)
    net.eval()
    correct = 0
    total = 0
    with torch.no_grad():
        for i, (images, labels) in enumerate(dataloader, 0):
            if i%100 == 0:
                print(i)
            images, labels = images.to(device), labels.to(device)
            outputs = net(images)
            _, predicted = torch.max(outputs.data, 1)
            fname, _ = dataloader.dataset.samples[i]
            out.write("test/{},{}\n".format(fname.split('/')[-1], idx_to_class[predicted.item()]))
    out.close()

model = torch.hub.load('pytorch/vision:v0.6.0', 'resnet18', pretrained=True)
model.fc = nn.Linear(512, 555) 

# model = torch.hub.load('pytorch/vision:v0.9.0', 'alexnet', pretrained=True)
# model.classifier[6] = nn.Linear(4096, 555)

losses = train(model, train_loader, epochs=1, schedule={0:.01, 5:.001}, 
               lr=.01, checkpoint_path=checkpoints)

plt.plot(smooth(losses, 50))

print("Training accuracy: %f" % accuracy(model, train_loader))
print("Validation accuracy: %f" % accuracy(model, val_loader))
predict(resnet, test_loader, checkpoints+'submissions.csv')
```